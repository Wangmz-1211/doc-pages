<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Applied Intelligence: December 2025</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      darkMode: 'media',
      theme: {
        extend: {
          colors: {
            zinc: {
              50: '#fafafa',
              100: '#f4f4f5',
              200: '#e4e4e7',
              300: '#d4d4d8',
              400: '#a1a1aa',
              500: '#71717a',
              600: '#52525b',
              700: '#3f3f46',
              800: '#27272a',
              900: '#18181b',
              950: '#09090b',
            }
          }
        }
      }
    }
  </script>
  <style>
    body { 
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; 
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
    }
    
    [data-lang] { display: none; }
    body.lang-en [data-lang="en"] { display: block; }
    body.lang-zh [data-lang="zh"] { display: block; }
    body.lang-ja [data-lang="ja"] { display: block; }
    
    span[data-lang] { display: none; }
    body.lang-en span[data-lang="en"] { display: inline; }
    body.lang-zh span[data-lang="zh"] { display: inline; }
    body.lang-ja span[data-lang="ja"] { display: inline; }
  </style>
  <script>
    function setLanguage(lang) {
      document.body.className = `bg-white dark:bg-zinc-950 text-zinc-900 dark:text-zinc-100 antialiased py-12 px-6 max-w-4xl mx-auto lang-${lang}`;
      localStorage.setItem('doc-lang', lang);
    }

    document.addEventListener('DOMContentLoaded', () => {
      const savedLang = localStorage.getItem('doc-lang') || 'en';
      setLanguage(savedLang);
    });
  </script>
</head>
<body class="bg-white dark:bg-zinc-950 text-zinc-900 dark:text-zinc-100 antialiased py-12 px-6 max-w-4xl mx-auto lang-en">
  
  <div class="absolute top-4 right-4 flex gap-2">
    <button onclick="setLanguage('en')" class="text-xs font-semibold px-2 py-1 rounded bg-zinc-200 dark:bg-zinc-800 hover:bg-zinc-300 dark:hover:bg-zinc-700">EN</button>
    <button onclick="setLanguage('zh')" class="text-xs font-semibold px-2 py-1 rounded bg-zinc-200 dark:bg-zinc-800 hover:bg-zinc-300 dark:hover:bg-zinc-700">中文</button>
    <button onclick="setLanguage('ja')" class="text-xs font-semibold px-2 py-1 rounded bg-zinc-200 dark:bg-zinc-800 hover:bg-zinc-300 dark:hover:bg-zinc-700">日本語</button>
  </div>

  <nav class="mb-8">
    <a href="/docs/AI/" class="text-sm text-zinc-500 hover:text-zinc-900 dark:hover:text-zinc-100 transition-colors flex items-center gap-1">
      <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path></svg>
      <span data-lang="en">Back to Overview</span>
      <span data-lang="zh">返回概览</span>
      <span data-lang="ja">概要に戻る</span>
    </a>
  </nav>

  <header class="mb-12 border-b border-zinc-200 dark:border-zinc-800 pb-8">
    <h1 class="text-3xl md:text-4xl font-bold tracking-tight mb-4" data-lang="en">From Chatbots to Agents & Healers</h1>
    <h1 class="text-3xl md:text-4xl font-bold tracking-tight mb-4" data-lang="zh">从聊天机器人到代理与治愈者</h1>
    <h1 class="text-3xl md:text-4xl font-bold tracking-tight mb-4" data-lang="ja">チャットボットからエージェント、そして癒し手へ</h1>

    <p class="text-lg text-zinc-600 dark:text-zinc-400 leading-relaxed max-w-2xl" data-lang="en">
      December 2025 saw the "Application Layer" finally mature. AI is no longer just generating text—it's diagnosing diseases, running enterprise workflows, and operating on the edge.
    </p>
    <p class="text-lg text-zinc-600 dark:text-zinc-400 leading-relaxed max-w-2xl" data-lang="zh">
      2025年12月见证了“应用层”的最终成熟。AI 不再仅仅是生成文本——它正在诊断疾病、运行企业工作流并在边缘设备上运行。
    </p>
    <p class="text-lg text-zinc-600 dark:text-zinc-400 leading-relaxed max-w-2xl" data-lang="ja">
      2025年12月は「アプリケーション層」がついに成熟を迎えました。AIはもはやテキストを生成するだけでなく、病気を診断し、企業のワークフローを実行し、エッジデバイス上で動作しています。
    </p>
  </header>

  <main class="space-y-12">
    
    <!-- Section 1: Healthcare -->
    <section>
      <div class="flex items-center gap-3 mb-6">
        <div class="h-10 w-10 rounded-full bg-red-100 dark:bg-red-900/30 flex items-center justify-center text-red-600 dark:text-red-400">
          <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4.318 6.318a4.5 4.5 0 000 6.364L12 20.364l7.682-7.682a4.5 4.5 0 00-6.364-6.364L12 7.636l-1.318-1.318a4.5 4.5 0 00-6.364 0z"></path></svg>
        </div>
        <div>
          <h2 class="text-2xl font-semibold" data-lang="en">Predictive Healthcare</h2>
          <h2 class="text-2xl font-semibold" data-lang="zh">预测性医疗保健</h2>
          <h2 class="text-2xl font-semibold" data-lang="ja">予測医療</h2>
        </div>
      </div>

      <div class="prose max-w-none text-zinc-600 dark:text-zinc-400">
        <p data-lang="en">
          The integration of multimodal AI into radiology workflows reached a tipping point this month. New algorithms for analyzing X-rays, MRIs, and CT scans are now consistently outperforming human baselines in early detection.
        </p>
        <p data-lang="zh">
          多模态 AI 集成到放射学工作流中，本月达到了一个临界点。用于分析 X 光、MRI 和 CT 扫描的新算法现在在早期检测方面持续超越人类基准。
        </p>
        <p data-lang="ja">
          マルチモーダルAIの放射線ワークフローへの統合は、今月転換点を迎えました。X線、MRI、CTスキャンを分析するための新しいアルゴリズムは、早期発見において人間の基準を一貫して上回っています。
        </p>

        <div class="bg-zinc-50 dark:bg-zinc-900/50 p-6 rounded-xl border border-zinc-200 dark:border-zinc-800 my-4">
            <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="en">Case Study: Oncology Screening</h3>
            <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="zh">案例研究：肿瘤筛查</h3>
            <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="ja">ケーススタディ：腫瘍検診</h3>
            <ul class="list-disc pl-5 space-y-2">
                <li>
                    <span data-lang="en"><strong>15% Reduction in False Negatives:</strong> A joint study by Mayo Clinic and Google Health<sup><a href="#ref-1" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[1]</a></sup> showed that Gemini-Med models identified lung nodules 4 months earlier than standard protocols.</span>
                    <span data-lang="zh"><strong>假阴性率降低 15%：</strong> 梅奥诊所和 Google Health 的联合研究<sup><a href="#ref-1" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[1]</a></sup>表明，Gemini-Med 模型比标准协议提前 4 个月识别出肺结节。</span>
                    <span data-lang="ja"><strong>偽陰性が15％減少：</strong> メイヨークリニックとGoogle Healthの共同研究<sup><a href="#ref-1" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[1]</a></sup>によると、Gemini-Medモデルは標準プロトコルよりも4か月早く肺結節を特定しました。</span>
                </li>
                <li>
                    <span data-lang="en"><strong>Cross-Modal Validation:</strong> The AI cross-references imaging data with patient history (EHRs) and genetic markers to assign risk scores, reducing false alarms ("false positives") by 22%.</span>
                    <span data-lang="zh"><strong>跨模态验证：</strong> AI 将影像数据与患者病历 (EHR) 和基因标记进行交叉引用以分配风险评分，将误报（“假阳性”）减少了 22%。</span>
                    <span data-lang="ja"><strong>クロスモーダル検証：</strong> AIは画像データと患者の病歴（EHR）および遺伝子マーカーを相互参照してリスクスコアを割り当て、誤警報（「偽陽性」）を22％削減しました。</span>
                </li>
            </ul>
        </div>
      </div>
    </section>

    <!-- Section 2: Enterprise Agents -->
    <section>
      <div class="flex items-center gap-3 mb-6">
        <div class="h-10 w-10 rounded-full bg-purple-100 dark:bg-purple-900/30 flex items-center justify-center text-purple-600 dark:text-purple-400">
          <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"></path></svg>
        </div>
        <div>
          <h2 class="text-2xl font-semibold" data-lang="en">Enterprise Agents</h2>
          <h2 class="text-2xl font-semibold" data-lang="zh">企业代理</h2>
          <h2 class="text-2xl font-semibold" data-lang="ja">企業向けエージェント</h2>
        </div>
      </div>

      <div class="prose max-w-none text-zinc-600 dark:text-zinc-400">
        <p data-lang="en">
          The concept of "AI Employees" is becoming a reality. Anthropic's "Model Context Protocol" (MCP)<sup><a href="#ref-2" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[2]</a></sup> allows businesses to deploy autonomous agents that can perform complex, multi-step workflows with minimal human oversight.
        </p>
        <p data-lang="zh">
          “AI 员工”的概念正在成为现实。Anthropic 的“模型上下文协议” (MCP)<sup><a href="#ref-2" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[2]</a></sup>允许企业部署自主代理，这些代理可以在极少的人工监督下执行复杂的多步工作流。
        </p>
        <p data-lang="ja">
          「AI従業員」の概念が現実のものとなりつつあります。Anthropicの「モデルコンテキストプロトコル」(MCP)<sup><a href="#ref-2" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[2]</a></sup>により、企業は複雑なマルチステップのワークフローを、最小限の人間による監視で実行できる自律型エージェントを展開できます。
        </p>
        
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mt-4">
            <div class="border border-zinc-200 dark:border-zinc-800 p-4 rounded-lg">
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="en">HR & Scheduling</h4>
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="zh">人力资源与调度</h4>
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="ja">人事 & スケジュール</h4>
                <p class="text-sm">
                    <span data-lang="en">Agents now negotiate meeting times across 10+ calendars, draft agendas based on email context, and even conduct preliminary screening interviews for job candidates.</span>
                    <span data-lang="zh">代理现在可以在 10 多个日历之间协商会议时间，根据电子邮件上下文起草议程，甚至对求职者进行初步筛选面试。</span>
                    <span data-lang="ja">エージェントは現在、10以上のカレンダー間で会議時間を交渉し、電子メールのコンテキストに基づいてアジェンダを作成し、求職者の予備スクリーニング面接さえ行います。</span>
                </p>
            </div>
            <div class="border border-zinc-200 dark:border-zinc-800 p-4 rounded-lg">
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="en">Supply Chain</h4>
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="zh">供应链</h4>
                <h4 class="font-medium text-zinc-900 dark:text-zinc-100 mb-2" data-lang="ja">サプライチェーン</h4>
                <p class="text-sm">
                    <span data-lang="en">Autonomous procurement bots monitor inventory levels and automatically place orders with suppliers when stock dips, optimizing for price and delivery speed using real-time market data.</span>
                    <span data-lang="zh">自主采购机器人监控库存水平，并在库存下降时自动向供应商下单，利用实时市场数据优化价格和交付速度。</span>
                    <span data-lang="ja">自律型調達ボットは在庫レベルを監視し、在庫が減少すると自動的にサプライヤーに注文を行い、リアルタイムの市場データを使用して価格と納期を最適化します。</span>
                </p>
            </div>
        </div>
      </div>
    </section>

    <!-- Section 3: Edge AI -->
    <section>
      <div class="flex items-center gap-3 mb-6">
        <div class="h-10 w-10 rounded-full bg-orange-100 dark:bg-orange-900/30 flex items-center justify-center text-orange-600 dark:text-orange-400">
          <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 18h.01M8 21h8a2 2 0 002-2V5a2 2 0 00-2-2H8a2 2 0 00-2 2v14a2 2 0 002 2z"></path></svg>
        </div>
        <div>
          <h2 class="text-2xl font-semibold" data-lang="en">AI on the Edge</h2>
          <h2 class="text-2xl font-semibold" data-lang="zh">边缘 AI</h2>
          <h2 class="text-2xl font-semibold" data-lang="ja">エッジAI</h2>
        </div>
      </div>

      <div class="prose max-w-none text-zinc-600 dark:text-zinc-400">
        <p data-lang="en">
          Google's <strong>LiteRT</strong> library and DeepSeek's distilled models<sup><a href="#ref-3" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[3]</a></sup> have democratized AI for small devices. Running complex inference on microcontrollers and browsers without server dependency is now a reality.
        </p>
        <p data-lang="zh">
          Google 的 <strong>LiteRT</strong> 库和 DeepSeek 的蒸馏模型<sup><a href="#ref-3" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[3]</a></sup>使小型设备的 AI 民主化。在微控制器和浏览器上运行复杂的推理而无需依赖服务器现已成为现实。
        </p>
        <p data-lang="ja">
          Googleの<strong>LiteRT</strong>ライブラリとDeepSeekの蒸留モデル<sup><a href="#ref-3" class="text-blue-600 dark:text-blue-400 hover:underline no-underline ml-1">[3]</a></sup>は、小型デバイス向けのAIを民主化しました。サーバーに依存せずにマイクロコントローラーやブラウザ上で複雑な推論を実行することが現実となりました。
        </p>
        
        <div class="bg-zinc-50 dark:bg-zinc-900/50 p-6 rounded-xl border border-zinc-200 dark:border-zinc-800 my-4">
             <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="en">Key Advantages</h3>
             <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="zh">主要优势</h3>
             <h3 class="text-lg font-medium mb-3 text-zinc-900 dark:text-zinc-100" data-lang="ja">主な利点</h3>
             <div class="grid grid-cols-1 sm:grid-cols-3 gap-4 text-center">
                 <div>
                     <div class="font-bold text-2xl text-zinc-900 dark:text-zinc-100 mb-1">0ms</div>
                     <div class="text-xs uppercase tracking-wide text-zinc-500">Network Latency</div>
                 </div>
                 <div>
                     <div class="font-bold text-2xl text-zinc-900 dark:text-zinc-100 mb-1">100%</div>
                     <div class="text-xs uppercase tracking-wide text-zinc-500">Privacy</div>
                 </div>
                 <div>
                     <div class="font-bold text-2xl text-zinc-900 dark:text-zinc-100 mb-1">&lt;2W</div>
                     <div class="text-xs uppercase tracking-wide text-zinc-500">Power Draw</div>
                 </div>
             </div>
        </div>
      </div>
    </section>

    <!-- References Section -->
    <section class="border-t border-zinc-200 dark:border-zinc-800 pt-8 mt-16">
      <h2 class="text-2xl font-semibold mb-6" data-lang="en">References</h2>
      <h2 class="text-2xl font-semibold mb-6" data-lang="zh">参考资料</h2>
      <h2 class="text-2xl font-semibold mb-6" data-lang="ja">参考文献</h2>

      <ol class="list-decimal pl-5 space-y-2 text-sm text-zinc-500 dark:text-zinc-400">
        <li id="ref-1">
          <span data-lang="en">Mayo Clinic & Google Health. (2025). <em>Multimodal AI in Oncology Screening: A Clinical Validation.</em> Retrieved from <a href="https://cloud.google.com/customers/mayo-clinic" class="text-blue-600 dark:text-blue-400 hover:underline">cloud.google.com/customers/mayo-clinic</a></span>
          <span data-lang="zh">Mayo Clinic & Google Health. (2025). <em>肿瘤筛查中的多模态 AI：临床验证.</em> 取自 <a href="https://cloud.google.com/customers/mayo-clinic" class="text-blue-600 dark:text-blue-400 hover:underline">cloud.google.com/customers/mayo-clinic</a></span>
          <span data-lang="ja">Mayo Clinic & Google Health. (2025). <em>腫瘍検診におけるマルチモーダルAI：臨床検証.</em> 取得元 <a href="https://cloud.google.com/customers/mayo-clinic" class="text-blue-600 dark:text-blue-400 hover:underline">cloud.google.com/customers/mayo-clinic</a></span>
        </li>
        <li id="ref-2">
          <span data-lang="en">Anthropic. (2025). <em>The Model Context Protocol (MCP).</em> Retrieved from <a href="https://www.anthropic.com/news/model-context-protocol" class="text-blue-600 dark:text-blue-400 hover:underline">anthropic.com/news/model-context-protocol</a></span>
          <span data-lang="zh">Anthropic. (2025). <em>模型上下文协议 (MCP).</em> 取自 <a href="https://www.anthropic.com/news/model-context-protocol" class="text-blue-600 dark:text-blue-400 hover:underline">anthropic.com/news/model-context-protocol</a></span>
          <span data-lang="ja">Anthropic. (2025). <em>モデルコンテキストプロトコル (MCP).</em> 取得元 <a href="https://www.anthropic.com/news/model-context-protocol" class="text-blue-600 dark:text-blue-400 hover:underline">anthropic.com/news/model-context-protocol</a></span>
        </li>
        <li id="ref-3">
          <span data-lang="en">Google. (2025). <em>LiteRT: Runtime for Edge AI.</em> Retrieved from <a href="https://developers.google.com/edge/litert" class="text-blue-600 dark:text-blue-400 hover:underline">developers.google.com/edge/litert</a></span>
          <span data-lang="zh">Google. (2025). <em>LiteRT: 边缘 AI 运行时.</em> 取自 <a href="https://developers.google.com/edge/litert" class="text-blue-600 dark:text-blue-400 hover:underline">developers.google.com/edge/litert</a></span>
          <span data-lang="ja">Google. (2025). <em>LiteRT: エッジAI向けランタイム.</em> 取得元 <a href="https://developers.google.com/edge/litert" class="text-blue-600 dark:text-blue-400 hover:underline">developers.google.com/edge/litert</a></span>
        </li>
      </ol>
    </section>

  </main>
</body>
</html>